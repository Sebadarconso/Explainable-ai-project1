# Explainable AI - Project 1

## Overview
This project focuses on developing an Explainable AI (XAI) solution for image classification. The primary objectives include implementing a 2D Convolutional Neural Network (CNN) for image classification and employing two eXplainable AI algorithms to extract the most crucial areas from the images. Subsequently, a comprehensive statistical analysis will be conducted on the final attributions to enhance interpretability and transparency in the decision-making process.

## Features

### 1. Image Classification with 2D CNN
   - Implement a 2D Convolutional Neural Network for accurate image classification.
   - Utilize state-of-the-art deep learning techniques to enhance classification performance.

### 2. Explainable AI Algorithms
   - Integrate two eXplainable AI algorithms to interpret and explain the decision-making process.
   - Improve model transparency by identifying and visualizing significant features in the images.

### 3. Statistical Analysis
   - Perform in-depth statistical analysis on the attributions obtained from the XAI algorithms.
   - Explore relationships between important image regions and classification outcomes.
